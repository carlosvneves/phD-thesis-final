{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}D:\Google Drive\_DOUTORADO\__TESE\__CODEandDATA\__TESE_code-data\efficiency\Stata\SFA\logSFA. 2 Mar 202117_55_02.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 2 Mar 2021, 17:55:02
{txt}
{com}. 
. /************************************************************************
> (3) ANÁLISE SFA, TOMANDO COMO VARIÁVEIS:
> - INPUTS: REC; CUST;
> - OUTPUTS: AVG 
> 
> OUTPUT ORIENTED
> *************************************************************************/
. * set the directory to the location of .ado files 
. * .ado files from:
. *
. * A Practitioner's Guide to Stochastic Frontier Analysis Using Stata         
. * Subal C. Kumbhakar, Hung-Jen Wang and Alan P. Horncastle                     
. *                                                                               
. //adopath ++ "C:\ado\personal\sfbook\sfbook_ado"
. 
. // apaga qualquer unidade que tenha valor de receita ou custo nulo 
. //drop if rec  <=0 
. //drop if cust <=0
. 
. /*
> subsititui os id's originais por id's para dados em painel (um id para cada concessionária)
> */
. // lista de concessionárias na base de dados 
. levelsof conc, local(concs)
{res}{txt}`"AUTOFERNAODIAS"' `"AUTOFLUMINENSE"' `"AUTOLITORALSUL"' `"AUTOPLANALTOSUL"' `"AUTOREGIS"' `"CCRPONTE"' `"CONCEBRA"' `"CONCEPA"' `"CONCER"' `"CRO"' `"CRT"' `"ECO101"' `"ECOPONTE"' `"ECOSUL"' `"MGORODOVIAS"' `"MSVIA"' `"NOVADUTRA"' `"RODOVIADOACO"' `"TRANSBRASILIANA"' `"VIA040"' `"VIABAHIA"'

{com}. // contador local para gerar id
. local count 1
{txt}
{com}. // loop na lista de concessionárias
. foreach v in `concs'{c -(}
{txt}  2{com}.         
.         // substitui o id original, para os casos em que há match entre o nome da
.         // concessionária na base e na lista de nomes 
.         quietly replace id = `count' if conc == "`v'"
{txt}  3{com}.         local ++count // atualiza o contador de id
{txt}  4{com}. {c )-}
{txt}
{com}. 
. // gera variáveis dummy para marcar as etapas
. quietly gen dEtapa2 = (etp==2)
{txt}
{com}. quietly gen dEtapa3 = (etp==3)
{txt}
{com}. 
. // Como a análise na parte (1) indicou não haver variação relevante nas variáveis ao longo do tempo, optou-se por calcular as médias do período das variáveis de input e output
. quietly bysort id: egen custm = mean(cust_km_adj)
{txt}
{com}. quietly bysort id: egen recm = mean(rec_km_adj)
{txt}
{com}. quietly bysort id: egen avgm = mean(avg)
{txt}
{com}. quietly bysort id: egen tarm = mean(tar_adj)
{txt}
{com}. // identifica duplicatas
. quietly by id: gen dup = cond(_N==1, 0, _n)
{txt}
{com}. // apaga duplicatas
. drop if dup > 1
{txt}(61 observations deleted)

{com}. 
. // gera índices para as DMUs
. quietly gen dmu = id
{txt}
{com}. 
. // apaga variáveis dispensáveis para a análise DEA
. //quietly drop id ano anoconc cust cust_km rec rec_km avg dup
. 
. // salva dados para simulação DEA
. save data_sfa, replace
{txt}file data_sfa.dta saved

{com}. 
. /*
> gera logaritmo das variáveis para a função de produção Cobb-Douglas
> 
> */
. gen l_rec = log(recm)
{txt}
{com}. gen l_cust = log(custm)
{txt}
{com}. gen l_avg = log(avgm)
{txt}
{com}. 
. // define inputs e outputs da análise SFA
. global inp l_cust l_rec
{txt}
{com}. global out l_avg
{txt}
{com}. 
. * variáveis explicativas
. global reglist npp ext tar dEtapa2 dEtapa3
{txt}
{com}. 
. ********************************************************************************************
. * Testa se o modelo especificado é válido antes de proceder com as estimativas
. * Foi utilizado o teste do terceiro momento do resíduo OLS (M3T) de Coelli (1995)
. * para checar se os resíduos são assimétricos para a esquerda, o que confirmaria
. * a possibilidade de ser utilizada a especificação para a função de produção. 
. * Para uma função de produção de fronteira estocástica, o erro composto(v - u), u > 0 e v
. * distribuído simetricamente em torno de zero, deve ter os resíduos da estimatica OLS
. * enviesadas para a esquerda. 
. ********************************************************************************************
. reg $out $inp

{txt}      Source {c |}       SS           df       MS      Number of obs   ={res}        21
{txt}{hline 13}{c +}{hline 34}   F(2, 18)        = {res}     0.71
{txt}       Model {c |} {res} .013145006         2  .006572503   {txt}Prob > F        ={res}    0.5067
{txt}    Residual {c |} {res} .167518403        18  .009306578   {txt}R-squared       ={res}    0.0728
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}   -0.0303
{txt}       Total {c |} {res} .180663408        20   .00903317   {txt}Root MSE        =   {res} .09647

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       l_avg{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}l_cust {c |}{col 14}{res}{space 2}-.0336523{col 26}{space 2} .0473419{col 37}{space 1}   -0.71{col 46}{space 3}0.486{col 54}{space 4}-.1331139{col 67}{space 3} .0658093
{txt}{space 7}l_rec {c |}{col 14}{res}{space 2} .0395258{col 26}{space 2} .0358908{col 37}{space 1}    1.10{col 46}{space 3}0.285{col 54}{space 4}-.0358781{col 67}{space 3} .1149297
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} 1.321686{col 26}{space 2} .1756892{col 37}{space 1}    7.52{col 46}{space 3}0.000{col 54}{space 4} .9525771{col 67}{space 3} 1.690796
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. predict e, residual
{txt}
{com}. sum e, detail

                          {txt}Residuals
{hline 61}
      Percentiles      Smallest
 1%    {res}-.2426055      -.2426055
{txt} 5%    {res}-.1241298      -.1241298
{txt}10%    {res}-.0845446      -.0845446       {txt}Obs         {res}         21
{txt}25%    {res}-.0576841      -.0617275       {txt}Sum of Wgt. {res}         21

{txt}50%    {res}-.0001136                      {txt}Mean          {res}-6.02e-10
                        {txt}Largest       Std. Dev.     {res} .0915201
{txt}75%    {res} .0673245        .098525
{txt}90%    {res}  .100082        .100082       {txt}Variance      {res} .0083759
{txt}95%    {res} .1187358       .1187358       {txt}Skewness      {res}-.6730419
{txt}99%    {res} .1353063       .1353063       {txt}Kurtosis      {res} 3.470593
{txt}
{com}. sktest e, noadj
{res}
{txt}Skewness and kurtosis tests for normality
{col 58}{hline 3} Joint test {hline 3}
{col 5}Variable {c |}{col 22}Obs   Pr(skewness)   Pr(kurtosis)   chi2(2)  Prob>chi2
{hline 13}{c +}{hline 61}
           e {c |}{res}{col 16}       21{col 34}0.1402{col 49}0.2716{col 56}     3.38{col 70}0.1841
{txt}
{com}. * notar que a distribuição é assimétrica para a esquerda (Skewness < 0)
. quietly sum e
{txt}
{com}. local e_mean = r(mean)
{txt}
{com}. local N = r(N)
{txt}
{com}. egen double m2 = mean((e - `e_mean')^2)
{txt}
{com}. egen double m3 = mean((e - `e_mean')^3)
{txt}
{com}. gen double M3T = m3/sqrt(6*((m2)^3)/`N')
{txt}
{com}. di "Como ", M3T[1], " é negativo, então os resíduos são assimétricos para a esquerda (rejeição de H0: não há assimetria). "
{res}Como  -1.2591461  é negativo, então os resíduos são assimétricos para a esquerda (rejeição de H0: não há assimetria). 
{txt}
{com}. 
. 
. *********************************************************************************************
. // (1) OLS - Fronteira determinística
. reg $out $inp, noconstant

{txt}      Source {c |}       SS           df       MS      Number of obs   ={res}        21
{txt}{hline 13}{c +}{hline 34}   F(2, 19)        = {res}   516.70
{txt}       Model {c |} {res} 37.7580912         2  18.8790456   {txt}Prob > F        ={res}    0.0000
{txt}    Residual {c |} {res} .694210324        19  .036537385   {txt}R-squared       ={res}    0.9819
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}    0.9800
{txt}       Total {c |} {res} 38.4523015        21  1.83106198   {txt}Root MSE        =   {res} .19115

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       l_avg{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}l_cust {c |}{col 14}{res}{space 2} .2181887{col 26}{space 2} .0663272{col 37}{space 1}    3.29{col 46}{space 3}0.004{col 54}{space 4} .0793643{col 67}{space 3}  .357013
{txt}{space 7}l_rec {c |}{col 14}{res}{space 2}-.0263974{col 26}{space 2} .0689621{col 37}{space 1}   -0.38{col 46}{space 3}0.706{col 54}{space 4}-.1707368{col 67}{space 3}  .117942
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. eststo OLS
{txt}
{com}. 
. esttab OLS using "sfaolsest.tex" , beta tex replace
{res}{txt}(output written to {browse  `"sfaolsest.tex"'})

{com}. 
. predict e_ols, residual /* salva o resíduo da estimativa OLS na variável e */
{txt}
{com}. quietly summarize e_ols /* obtém as estatísticas sem imprimir nada na tela */
{txt}
{com}. gen double eff_ols = exp(e_ols)
{txt}
{com}. summarize eff_ols

{txt}    Variable {c |}        Obs        Mean    Std. Dev.       Min        Max
{hline 13}{c +}{hline 57}
{space 5}eff_ols {c |}{res}         21     1.03627    .1996888   .6962408   1.623159
{txt}
{com}. 
. *********************************************************************************************
. // (2) COLS - Fronteira determinística (OLS Corrigido)
. reg $out $inp, noconstant

{txt}      Source {c |}       SS           df       MS      Number of obs   ={res}        21
{txt}{hline 13}{c +}{hline 34}   F(2, 19)        = {res}   516.70
{txt}       Model {c |} {res} 37.7580912         2  18.8790456   {txt}Prob > F        ={res}    0.0000
{txt}    Residual {c |} {res} .694210324        19  .036537385   {txt}R-squared       ={res}    0.9819
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}    0.9800
{txt}       Total {c |} {res} 38.4523015        21  1.83106198   {txt}Root MSE        =   {res} .19115

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       l_avg{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}l_cust {c |}{col 14}{res}{space 2} .2181887{col 26}{space 2} .0663272{col 37}{space 1}    3.29{col 46}{space 3}0.004{col 54}{space 4} .0793643{col 67}{space 3}  .357013
{txt}{space 7}l_rec {c |}{col 14}{res}{space 2}-.0263974{col 26}{space 2} .0689621{col 37}{space 1}   -0.38{col 46}{space 3}0.706{col 54}{space 4}-.1707368{col 67}{space 3}  .117942
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. eststo COLS
{txt}
{com}. 
. esttab COLS using "sfacolsest.tex" , beta tex replace
{res}{txt}(output written to {browse  `"sfacolsest.tex"'})

{com}. 
. 
. predict e_cols, residual /* salva o resíduo da estimativa OLS na variável e */
{txt}
{com}. quietly summarize e_cols /* obtém as estatísticas sem imprimir nada na tela */
{txt}
{com}. gen double u_star = -(e_cols - r(max)) /* obtém ineficiência a partir dos resíduos corrigidos */ 
{txt}
{com}. gen double eff_cols = exp(-u_star) /* calcula eficiência técnica */
{txt}
{com}. summarize eff_cols

{txt}    Variable {c |}        Obs        Mean    Std. Dev.       Min        Max
{hline 13}{c +}{hline 57}
{space 4}eff_cols {c |}{res}         21    .6384277    .1230248   .4289418          1
{txt}
{com}. list conc u_star eff_cols
{txt}
     {c TLC}{hline 17}{c -}{hline 11}{c -}{hline 11}{c TRC}
     {c |} {res}           conc      u_star    eff_cols {txt}{c |}
     {c LT}{hline 17}{c -}{hline 11}{c -}{hline 11}{c RT}
  1. {c |} {res} AUTOFERNAODIAS   .57790539   .56107237 {txt}{c |}
  2. {c |} {res} AUTOFLUMINENSE   .55370738    .5748148 {txt}{c |}
  3. {c |} {res} AUTOLITORALSUL    .5682221   .56653178 {txt}{c |}
  4. {c |} {res}AUTOPLANALTOSUL   .48921015   .61311047 {txt}{c |}
  5. {c |} {res}      AUTOREGIS   .45868563   .63211393 {txt}{c |}
     {c LT}{hline 17}{c -}{hline 11}{c -}{hline 11}{c RT}
  6. {c |} {res}       CCRPONTE    .7701945   .46292302 {txt}{c |}
  7. {c |} {res}       CONCEBRA   .42414844   .65432675 {txt}{c |}
  8. {c |} {res}        CONCEPA   .84643397   .42894183 {txt}{c |}
  9. {c |} {res}         CONCER   .62420855   .53568523 {txt}{c |}
 10. {c |} {res}            CRO   .37809358   .68516638 {txt}{c |}
     {c LT}{hline 17}{c -}{hline 11}{c -}{hline 11}{c RT}
 11. {c |} {res}            CRT    .3586407   .69862532 {txt}{c |}
 12. {c |} {res}         ECO101   .39188933    .6757789 {txt}{c |}
 13. {c |} {res}       ECOPONTE   .59887905   .54942717 {txt}{c |}
 14. {c |} {res}         ECOSUL           0           1 {txt}{c |}
 15. {c |} {res}    MGORODOVIAS   .37881842   .68466992 {txt}{c |}
     {c LT}{hline 17}{c -}{hline 11}{c -}{hline 11}{c RT}
 16. {c |} {res}          MSVIA   .52882733   .58929561 {txt}{c |}
 17. {c |} {res}      NOVADUTRA    .5253009   .59137739 {txt}{c |}
 18. {c |} {res}   RODOVIADOACO   .25353843   .77604992 {txt}{c |}
 19. {c |} {res}TRANSBRASILIANA   .23650214   .78938419 {txt}{c |}
 20. {c |} {res}         VIA040   .32925661   .71945837 {txt}{c |}
     {c LT}{hline 17}{c -}{hline 11}{c -}{hline 11}{c RT}
 21. {c |} {res}       VIABAHIA   .48089685   .61822868 {txt}{c |}
     {c BLC}{hline 17}{c -}{hline 11}{c -}{hline 11}{c BRC}

{com}. 
. *********************************************************************************************
. * (3) CMAD - Corrected Mean absolute Deviation 
. qreg $out $inp /* regressão quantílica - utiliza a mediana */
{txt}Iteration  1:  WLS sum of weighted deviations = {res} .73159192

{txt}Iteration  1: sum of abs. weighted deviations = {res} .73190012
{txt}Iteration  2: sum of abs. weighted deviations = {res} .72797012

{txt}Median regression{col 53}Number of obs = {res}        21
{txt}  Raw sum of deviations{res} .8023613{txt} (about {res}1.3862944{txt})
  Min sum of deviations{res} .7279701{col 53}{txt}Pseudo R2     = {res}    0.0927

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       l_avg{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}l_cust {c |}{col 14}{res}{space 2}-.0422098{col 26}{space 2} .0833144{col 37}{space 1}   -0.51{col 46}{space 3}0.619{col 54}{space 4}-.2172468{col 67}{space 3} .1328272
{txt}{space 7}l_rec {c |}{col 14}{res}{space 2}  .046818{col 26}{space 2} .0631623{col 37}{space 1}    0.74{col 46}{space 3}0.468{col 54}{space 4}-.0858811{col 67}{space 3} .1795172
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}  1.32528{col 26}{space 2} .3091859{col 37}{space 1}    4.29{col 46}{space 3}0.000{col 54}{space 4} .6757045{col 67}{space 3} 1.974855
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}

{com}. eststo CMAD
{txt}
{com}. 
. esttab CMAD using "sfacmadest.tex" , beta tex replace
{res}{txt}(output written to {browse  `"sfacmadest.tex"'})

{com}. 
. estout CMAD, style(tex)
{res}
            &        CMAD\\
            &           b\\
l_cust      &   -.0422098\\
l_rec       &     .046818\\
_cons       &     1.32528\\
{txt}
{com}. 
. predict e_cmad, residual /* salva o resíduo da estimativa OLS na variável e */
{txt}
{com}. quietly summarize e_cmad /* obtém as estatísticas sem imprimir nada na tela */
{txt}
{com}. gen double eta_star_q = -(e_cmad - r(max)) /* obtém ineficiência a partir dos resíduos corrigidos */ 
{txt}
{com}. gen double eff_cmad = exp(-eta_star_q) /* calcula eficiência técnica */
{txt}
{com}. 
. 
. *********************************************************************************************
. * (4) Cobb-Douglas Half-Normal Model
. frontier $out $inp, noconstant
{res}
{txt}Iteration 0:{space 3}log likelihood = {res:-10114.832}  (not concave)
Iteration 1:{space 3}log likelihood = {res:-28.072714}  (not concave)
Iteration 2:{space 3}log likelihood = {res: 2.3364675}  (not concave)
Iteration 3:{space 3}log likelihood = {res: 3.1278914}  
Iteration 4:{space 3}log likelihood = {res:  3.774314}  (not concave)
Iteration 5:{space 3}log likelihood = {res: 4.0440434}  
Iteration 6:{space 3}log likelihood = {res: 4.4609127}  (not concave)
Iteration 7:{space 3}log likelihood = {res: 4.5470799}  
Iteration 8:{space 3}log likelihood = {res: 4.7770361}  
Iteration 9:{space 3}log likelihood = {res: 4.8036979}  (backed up)
Iteration 10:{space 2}log likelihood = {res: 4.8075957}  
Iteration 11:{space 2}log likelihood = {res: 4.8361822}  
Iteration 12:{space 2}log likelihood = {res: 4.8373179}  (backed up)
Iteration 13:{space 2}log likelihood = {res: 4.8391121}  (backed up)
Iteration 14:{space 2}log likelihood = {res: 4.8404451}  
Iteration 15:{space 2}log likelihood = {res: 4.8416125}  
Iteration 16:{space 2}log likelihood = {res: 4.8429258}  
Iteration 17:{space 2}log likelihood = {res: 4.8430676}  
Iteration 18:{space 2}log likelihood = {res: 4.8432171}  
Iteration 19:{space 2}log likelihood = {res: 4.8433019}  
Iteration 20:{space 2}log likelihood = {res: 4.8433603}  
Iteration 21:{space 2}log likelihood = {res: 4.8433841}  
Iteration 22:{space 2}log likelihood = {res: 4.8434076}  
Iteration 23:{space 2}log likelihood = {res: 4.8434224}  
Iteration 24:{space 2}log likelihood = {res: 4.8434319}  
Iteration 25:{space 2}log likelihood = {res:  4.843438}  
Iteration 26:{space 2}log likelihood = {res:  4.843442}  
Iteration 27:{space 2}log likelihood = {res: 4.8434446}  
Iteration 28:{space 2}log likelihood = {res: 4.8434464}  
Iteration 29:{space 2}log likelihood = {res: 4.8434473}  
Iteration 30:{space 2}log likelihood = {res:  4.843448}  
Iteration 31:{space 2}log likelihood = {res: 4.8434486}  
{res}
{txt}Stoc. frontier normal/half-normal model{col 49}Number of obs{col 67}= {res}        21
{txt}{col 49}Wald chi2({res}2{txt}){col 67}= {res}  2.73e+10
{txt}Log likelihood = {res} 4.8434486{txt}{col 49}Prob > chi2{col 67}= {res}    0.0000

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       l_avg{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}l_cust {c |}{col 14}{res}{space 2} .0526276{col 26}{space 2} 1.80e-06{col 37}{space 1} 2.9e+04{col 46}{space 3}0.000{col 54}{space 4} .0526241{col 67}{space 3} .0526311
{txt}{space 7}l_rec {c |}{col 14}{res}{space 2} .1932194{col 26}{space 2} 2.13e-06{col 37}{space 1} 9.1e+04{col 46}{space 3}0.000{col 54}{space 4} .1932153{col 67}{space 3} .1932236
{txt}{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
    /lnsig2v {c |}{col 14}{res}{space 2}-38.51277{col 26}{space 2} 768.1164{col 37}{space 1}   -0.05{col 46}{space 3}0.960{col 54}{space 4}-1543.993{col 67}{space 3} 1466.968
{txt}    /lnsig2u {c |}{col 14}{res}{space 2}-1.912864{col 26}{space 2} .3086067{col 37}{space 1}   -6.20{col 46}{space 3}0.000{col 54}{space 4}-2.517722{col 67}{space 3}-1.308006
{txt}{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
     sigma_v {c |}{col 14}{res}{space 2} 4.34e-09{col 26}{space 2} 1.67e-06{col 54}{space 4}        0{col 67}{space 3}        .
{txt}     sigma_u {c |}{col 14}{res}{space 2} .3842616{col 26}{space 2} .0592928{col 54}{space 4} .2839774{col 67}{space 3} .5199603
{txt}      sigma2 {c |}{col 14}{res}{space 2}  .147657{col 26}{space 2} .0455679{col 54}{space 4} .0583455{col 67}{space 3} .2369685
{txt}      lambda {c |}{col 14}{res}{space 2} 8.86e+07{col 26}{space 2} .0592928{col 54}{space 4} 8.86e+07{col 67}{space 3} 8.86e+07
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
LR test of sigma_u=0: {help j_chibar##|_new:chibar2(01) = }{res}0.00{col 56}{txt}Prob >= chibar2 = {res}1.000
{txt}
{com}. eststo sfa_hn
{txt}
{com}. 
. esttab sfa_hn using "sfa_hnest.tex" , beta tex replace
{res}{txt}(output written to {browse  `"sfa_hnest.tex"'})

{com}. 
. predict e_hn, u /* salva o resíduo da estimativa OLS na variável e */
{txt}
{com}. quietly summarize e_hn /* obtém as estatísticas sem imprimir nada na tela */
{txt}
{com}. gen double eta_hn= -(e_hn - r(max)) /* obtém ineficiência a partir dos resíduos corrigidos */ 
{txt}
{com}. gen double eff_hn = exp(-eta_hn) /* calcula eficiência técnica */
{txt}
{com}. 
. 
. 
. *********************************************************************************************
. * (5) Cobb-Douglas Exponential Model
. frontier $out $inp, distribution(exponential) noconstant
{res}
{txt}Iteration 0:{space 3}log likelihood = {res:-4500.2848}  (not concave)
Iteration 1:{space 3}log likelihood = {res:-511.01984}  (not concave)
Iteration 2:{space 3}log likelihood = {res:-118.67835}  (not concave)
Iteration 3:{space 3}log likelihood = {res:-86.847099}  (not concave)
Iteration 4:{space 3}log likelihood = {res:-83.472777}  (not concave)
Iteration 5:{space 3}log likelihood = {res:-82.647762}  (not concave)
Iteration 6:{space 3}log likelihood = {res:-82.237782}  (not concave)
Iteration 7:{space 3}log likelihood = {res: -82.21223}  (not concave)
Iteration 8:{space 3}log likelihood = {res:-82.199457}  (not concave)
Iteration 9:{space 3}log likelihood = {res: -82.19786}  (not concave)
Iteration 10:{space 2}log likelihood = {res:-82.197062}  (not concave)
Iteration 11:{space 2}log likelihood = {res:-82.197012}  (not concave)
Iteration 12:{space 2}log likelihood = {res:-82.196987}  (not concave)
Iteration 13:{space 2}log likelihood = {res:-82.196984}  (not concave)
Iteration 14:{space 2}log likelihood = {res:-82.196982}  (not concave)
Iteration 15:{space 2}log likelihood = {res:-82.196982}  (not concave)
Iteration 16:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 17:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 18:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 19:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 20:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 21:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 22:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 23:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 24:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 25:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 26:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 27:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 28:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 29:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 30:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 31:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 32:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 33:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 34:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 35:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 36:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 37:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 38:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 39:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 40:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 41:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 42:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 43:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 44:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 45:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 46:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 47:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 48:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 49:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 50:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 51:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 52:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 53:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 54:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 55:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 56:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 57:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 58:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 59:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 60:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 61:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 62:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 63:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 64:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 65:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 66:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 67:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 68:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 69:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 70:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 71:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 72:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 73:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 74:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 75:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 76:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 77:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 78:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 79:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 80:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 81:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 82:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 83:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 84:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 85:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 86:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 87:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 88:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 89:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 90:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 91:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 92:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 93:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 94:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 95:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 96:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 97:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 98:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 99:{space 2}log likelihood = {res:-82.196981}  (not concave)
Iteration 100:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 101:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 102:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 103:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 104:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 105:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 106:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 107:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 108:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 109:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 110:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 111:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 112:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 113:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 114:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 115:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 116:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 117:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 118:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 119:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 120:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 121:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 122:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 123:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 124:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 125:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 126:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 127:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 128:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 129:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 130:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 131:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 132:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 133:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 134:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 135:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 136:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 137:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 138:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 139:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 140:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 141:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 142:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 143:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 144:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 145:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 146:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 147:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 148:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 149:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 150:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 151:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 152:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 153:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 154:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 155:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 156:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 157:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 158:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 159:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 160:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 161:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 162:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 163:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 164:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 165:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 166:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 167:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 168:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 169:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 170:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 171:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 172:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 173:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 174:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 175:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 176:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 177:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 178:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 179:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 180:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 181:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 182:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 183:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 184:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 185:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 186:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 187:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 188:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 189:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 190:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 191:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 192:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 193:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 194:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 195:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 196:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 197:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 198:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 199:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 200:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 201:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 202:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 203:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 204:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 205:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 206:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 207:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 208:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 209:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 210:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 211:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 212:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 213:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 214:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 215:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 216:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 217:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 218:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 219:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 220:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 221:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 222:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 223:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 224:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 225:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 226:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 227:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 228:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 229:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 230:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 231:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 232:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 233:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 234:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 235:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 236:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 237:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 238:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 239:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 240:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 241:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 242:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 243:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 244:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 245:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 246:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 247:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 248:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 249:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 250:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 251:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 252:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 253:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 254:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 255:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 256:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 257:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 258:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 259:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 260:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 261:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 262:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 263:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 264:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 265:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 266:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 267:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 268:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 269:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 270:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 271:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 272:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 273:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 274:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 275:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 276:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 277:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 278:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 279:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 280:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 281:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 282:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 283:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 284:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 285:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 286:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 287:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 288:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 289:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 290:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 291:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 292:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 293:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 294:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 295:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 296:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 297:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 298:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 299:{space 1}log likelihood = {res:-82.196981}  (not concave)
Iteration 300:{space 1}log likelihood = {res:-82.196981}  (not concave)
{err}convergence not achieved
{res}
{txt}Stoc. frontier normal/exponential model{col 49}Number of obs{col 67}= {res}        21
{txt}{col 49}Wald chi2({res}2{txt}){col 67}= {res}  13398.54
{txt}Log likelihood = {res}-82.196981{txt}{col 49}Prob > chi2{col 67}= {res}    0.0000

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       l_avg{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}l_cust {c |}{col 14}{res}{space 2} .2028192{col 26}{space 2} .0184177{col 37}{space 1}   11.01{col 46}{space 3}0.000{col 54}{space 4} .1667212{col 67}{space 3} .2389172
{txt}{space 7}l_rec {c |}{col 14}{res}{space 2}   -.0108{col 26}{space 2}  .019145{col 37}{space 1}   -0.56{col 46}{space 3}0.573{col 54}{space 4}-.0483236{col 67}{space 3} .0267235
{txt}{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
    /lnsig2v {c |}{col 14}{res}{space 2}-5.879032{col 26}{space 2}  .090046{col 37}{space 1}  -65.29{col 46}{space 3}0.000{col 54}{space 4}-6.055519{col 67}{space 3}-5.702546
{txt}    /lnsig2u {c |}{col 14}{res}{space 2}-12.59129{col 26}{space 2}        .{col 37}{space 1}       .{col 46}{space 3}    .{col 54}{space 4}        .{col 67}{space 3}        .
{txt}{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
     sigma_v {c |}{col 14}{res}{space 2} .0528913{col 26}{space 2} .0023813{col 54}{space 4}  .048424{col 67}{space 3} .0577707
{txt}     sigma_u {c |}{col 14}{res}{space 2} .0018443{col 26}{space 2}        .{col 54}{space 4}        .{col 67}{space 3}        .
{txt}      sigma2 {c |}{col 14}{res}{space 2} .0028009{col 26}{space 2}        .{col 54}{space 4}        .{col 67}{space 3}        .
{txt}      lambda {c |}{col 14}{res}{space 2}   .03487{col 26}{space 2}        .{col 54}{space 4}        .{col 67}{space 3}        .
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{err}convergence not achieved
{txt}{search r(430), local:r(430);}

end of do-file

{search r(430), local:r(430);}

{com}. do "D:\Google Drive\_DOUTORADO\__TESE\__CODEandDATA\__TESE_code-data\efficiency\Stata\2021.02.23.SFA.2012-2016.do"
{txt}
{com}. *! Version 2021.02.23
. ********************************************************************************
. * Author: Carlos Eduardo Veras Neves                                                                       *
. *                                                                              *
. * Estimation of Technical Efficiency with SFA and DEA for Brazilian            *
. * Federal Toll Road Concessions 
. *                                                                              *
. ********************************************************************************
. * configuração inicial
. set trace off
{txt}
{com}. 
. clear all
{res}{txt}
{com}. 
. set more off
{txt}
{com}. 
. capture log close
{smcl}
{com}{sf}{ul off}